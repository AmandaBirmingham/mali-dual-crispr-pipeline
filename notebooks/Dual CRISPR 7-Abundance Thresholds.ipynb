{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dual CRISPR Screen Analysis\n",
    "# Step 7: Abundance Thresholds\n",
    "Amanda Birmingham, CCBB, UCSD (abirmingham@ucsd.edu)\n",
    "\n",
    "## Instructions\n",
    "\n",
    "To run this notebook reproducibly, follow these steps:\n",
    "1. Click **Kernel** > **Restart & Clear Output**\n",
    "2. When prompted, click the red **Restart & clear all outputs** button\n",
    "3. Fill in the values for your analysis for each of the variables in the [Input Parameters](#Input-Parameters) section\n",
    "4. Click **Cell** > **Run All**\n",
    "\n",
    "## Input Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g_timestamp = \"\"\n",
    "g_dataset_name = \"20160706_HeLa_A549_CV4\"\n",
    "g_count_alg_name = 'heuristic_v1'\n",
    "g_prepped_counts_run_prefix = \"A549_CV4_counts_w_everything_pseudo\"\n",
    "g_prepped_counts_dir = ('/Users/Birmingham/Work/Repositories/ccbb_tickets_2017/mali-dual-crispr-pipeline/src/python/'\n",
    "    'test_files/known_goods')\n",
    "g_min_count_limit = 10 #Note: in absolute counts, not log2.  Unchanged from earlier--10 seems to work well.\n",
    "g_max_fraction_acceptable_spline_density_diff = 0.02 # % of diff between max spline and min density\n",
    "g_max_fraction_counts_excluded = 0.95 # any threshold throwing out >x% of counts is not acceptable\n",
    "g_thresholds_dir = ('/Users/Birmingham/Work/Repositories/ccbb_tickets_2017/mali-dual-crispr-pipeline/src/python/'\n",
    "    'test_files/test_outputs/notebook7_A549_CV4_counts_w_everything')\n",
    "g_thresholds_run_prefix = \"A549_CV4_counts_w_everything\"\n",
    "g_code_location = '/Users/Birmingham/Work/Repositories/ccbb_tickets_2017/mali-dual-crispr-pipeline/src/python/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automated Set-Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import inspect\n",
    "import sys\n",
    "sys.path.append(g_code_location)\n",
    "\n",
    "import ccbbucsd.utilities.analysis_run_prefixes as ns_runs\n",
    "import ccbbucsd.utilities.files_and_paths as ns_files\n",
    "import ccbbucsd.utilities.notebook_logging as ns_logs\n",
    "\n",
    "\n",
    "def describe_var_list(input_var_name_list):\n",
    "    description_list =  [\"{0}: {1}\\n\".format(name, eval(name)) for name in input_var_name_list]\n",
    "    return \"\".join(description_list)\n",
    "\n",
    "\n",
    "ns_logs.set_stdout_info_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g_timestamp = ns_runs.check_or_set(g_timestamp, ns_runs.get_timestamp())\n",
    "g_thresholds_run_prefix = ns_runs.check_or_set(g_thresholds_run_prefix,\n",
    "    ns_runs.get_run_prefix(g_dataset_name, g_count_alg_name, g_timestamp))\n",
    "print(describe_var_list(['g_timestamp', 'g_thresholds_run_prefix']))\n",
    "ns_files.verify_or_make_dir(g_thresholds_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R Magic Import and Set-Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from rpy2.robjects import r\n",
    "import rpy2.robjects as robjects\n",
    "\n",
    "gR = robjects.r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring-Ready Counts File Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ccbbucsd.malicrispr.scoring_prep as ns_prep\n",
    "print(inspect.getsource(ns_prep.get_prepped_file_suffix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ccbbucsd.malicrispr.construct_file_extracter as ns_extracter\n",
    "print(inspect.getsource(ns_extracter.get_construct_header))\n",
    "print(inspect.getsource(ns_extracter.get_potential_annotation_headers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "def get_prepped_counts_only_df(prepped_counts_dir, prepped_counts_run_prefix):\n",
    "    prepped_counts_suffix = ns_prep.get_prepped_file_suffix()\n",
    "    prepped_counts_fp = ns_files.build_multipart_fp(prepped_counts_dir, [prepped_counts_run_prefix, \n",
    "                                                                         prepped_counts_suffix])       \n",
    "    prepped_counts_df = pandas.read_table(prepped_counts_fp, index_col=ns_extracter.get_construct_header())\n",
    "    total_headers = list(prepped_counts_df.columns.values)\n",
    "    unwanted_headers = ns_extracter.get_potential_annotation_headers()\n",
    "    count_headers = [x for x in total_headers if x not in unwanted_headers]\n",
    "    return prepped_counts_df.loc[:, count_headers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g_prepped_counts_only_df = get_prepped_counts_only_df(g_prepped_counts_dir, g_prepped_counts_run_prefix)\n",
    "g_prepped_counts_only_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Transfer from Python to R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 'temp' assignments suppress printing of cruft stdout\n",
    "temp = gR.assign('gPreppedCountsDf', g_prepped_counts_only_df)\n",
    "temp = gR.assign('gMinCountLimit', g_min_count_limit)\n",
    "temp = gR.assign('gMaxFractionAcceptableSplineDensityDiff', g_max_fraction_acceptable_spline_density_diff)\n",
    "temp = gR.assign('gMaxFractionCountsExcluded', g_max_fraction_counts_excluded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  R Set-Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "options(jupyter.plot_mimetypes = c(\"text/plain\", \"image/png\" ))\n",
    "options(repr.plot.width=7, repr.plot.height=7)    \n",
    "options(digits=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abundance-Threshold Identification Heuristic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "gManualColor = \"black\"\n",
    "gMinimumsColor = \"orange\"\n",
    "gMaximumsColor = \"turquoise\"\n",
    "gHistogramColor = \"blue\"\n",
    "gDensityColor = \"lightgreen\"\n",
    "gSplineColor = \"lightpink\"\n",
    "gChosenColor = \"red\"\n",
    "gSpar = NULL\n",
    "\n",
    "\n",
    "extremumIsAcceptable<-function(putativeThreshold, hist, maxCountFractionExcluded){\n",
    "    result = FALSE\n",
    "    if (!is.null(putativeThreshold)) {\n",
    "        fractionCountsExcluded = getFractionCountsExcluded(hist, putativeThreshold, \n",
    "            maxCountFractionExcluded)\n",
    "        result = fractionCountsExcluded<maxCountFractionExcluded\n",
    "    }\n",
    "    return(result)\n",
    "}\n",
    "    \n",
    "\n",
    "getFractionCountsExcluded<-function(hist, putativeThreshold, maxCountFractionExcluded){\n",
    "    tempHistDf = data.frame(mids=hist$mids, counts=hist$counts)\n",
    "    eligibleHistDf = tempHistDf[which(hist$mids<putativeThreshold), ]\n",
    "    result = sum(eligibleHistDf$counts)/sum(hist$counts)  \n",
    "    return(result)    \n",
    "}\n",
    "\n",
    "findExtremaIndices<-function(objWithXandY, getMins=TRUE){\n",
    "    relevantDiff = if(getMins==TRUE) 2 else -2\n",
    "    indicesOfExtrema = which(diff(sign(diff(objWithXandY$y)))==relevantDiff)+1\n",
    "    return(indicesOfExtrema) \n",
    "}\n",
    "        \n",
    "getlog2CountsAndFreqsAtExtrema<-function(densityObj, indicesOfExtrema){\n",
    "    log2CountsAtExtrema = densityObj$x[indicesOfExtrema]\n",
    "    densityFunc = approxfun(densityObj)\n",
    "    freqsAtExtrema = densityFunc(log2CountsAtExtrema)\n",
    "    result = data.frame(log2CountsAtExtrema, freqsAtExtrema)\n",
    "    result = result[with(result, order(log2CountsAtExtrema)), ]   \n",
    "    return(result)    \n",
    "}\n",
    "        \n",
    "# general concept: identify the peak of the \"main distribution\", then look for the lowest point in the\n",
    "# \"valley\" between it and the noise spike at the low end of the counts histogram.  \n",
    "# Not all count distributions have this general shape; for all known cases that don't, this method\n",
    "# will return NULL (rather than just silently picking a bad threshold).  \n",
    "findSmallestMinLeftOfMax<-function(splineWithXandY, minCountLimit, hist, maxCountFractionExcluded){\n",
    "    minLog2CountThreshold = log2(minCountLimit)\n",
    "    result = NULL # assume failure\n",
    "    \n",
    "    #look for row indices of local interior maxima and local interior minima in input spline curve\n",
    "    indicesOfMaxes = findExtremaIndices(splineWithXandY, FALSE)\n",
    "    indicesOfMins = findExtremaIndices(splineWithXandY, TRUE)\n",
    "    \n",
    "    # give up if there aren't at least one of each; otherwise\n",
    "    if (length(indicesOfMaxes)>0 & length(indicesOfMins)>0){\n",
    "        # get x and y values in the rows representing the local interior maxima\n",
    "        xAndYatMaxesDf = getlog2CountsAndFreqsAtExtrema(splineWithXandY, indicesOfMaxes)\n",
    "        eligibleMaxesDf = xAndYatMaxesDf[which(\n",
    "            xAndYatMaxesDf$log2CountsAtExtrema >= minLog2CountThreshold), ]\n",
    "\n",
    "        # if there are no local interior maxima at x values gte the global minimum allowed, give up; otherwise\n",
    "        if (nrow(eligibleMaxesDf)>0){\n",
    "            # pick the x position of the eligible local interior maximum with the largest y value\n",
    "            chosenMaxDf = eligibleMaxesDf[which(\n",
    "                eligibleMaxesDf$freqsAtExtrema == max(eligibleMaxesDf$freqsAtExtrema)), ]\n",
    "            rightmostLog2Count = chosenMaxDf$log2CountsAtExtrema[1]    \n",
    "\n",
    "            # get x and y values in the rows representing the local interior minima\n",
    "            xAndYatMinsDf = getlog2CountsAndFreqsAtExtrema(splineWithXandY, indicesOfMins)\n",
    "            eligibleMinsDf = xAndYatMinsDf[which(\n",
    "                xAndYatMinsDf$log2CountsAtExtrema >= minLog2CountThreshold &\n",
    "                xAndYatMinsDf$log2CountsAtExtrema < rightmostLog2Count), ]\n",
    "\n",
    "            # if there are no local interior minima with x values gte the global minimum allowed and\n",
    "            # lt the x position of the chosen maximum, give up; otherwise            \n",
    "            if (nrow(eligibleMinsDf)>0){\n",
    "                # pick the x position of the eligible local interior minimum with the smallest y value\n",
    "                chosenMinDf = eligibleMinsDf[which(\n",
    "                    eligibleMinsDf$freqsAtExtrema == min(eligibleMinsDf$freqsAtExtrema)), ] \n",
    "                putativeResult = chosenMinDf$log2CountsAtExtrema\n",
    "                # Only known situation where above logic picks a bad threshold is when all \"real\" \n",
    "                # data is monotonically decreasing but there is (at least one) minute local maximum \n",
    "                # in the noise at far right of the count distribution; extremumIsAcceptable sanity-checks\n",
    "                # for that pathological case.\n",
    "                if (extremumIsAcceptable(putativeResult, hist, maxCountFractionExcluded)){\n",
    "                    result = putativeResult\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return(result)\n",
    "}\n",
    "\n",
    "# helper for findSplineAndDensityNearPoint\n",
    "makeSplineAndDensityDf<-function(scaledDensityXandY, splineXandY){\n",
    "    # Determine spline and (scaled) density y values at shared set of x values \n",
    "    # where neither is NA, then calculate difference between spline and density\n",
    "    # at each of those points.\n",
    "    splineFunc = approxfun(splineXandY)\n",
    "    splineYAtDensityX = splineFunc(scaledDensityXandY$x)\n",
    "    result = data.frame(x=scaledDensityXandY$x, splineY=splineYAtDensityX, \n",
    "        densityY=scaledDensityXandY$y)\n",
    "    result = na.omit(result)\n",
    "    result$y = result$splineY-result$densityY \n",
    "    return(result)\n",
    "} \n",
    "\n",
    "\n",
    "# helper for findSplineAndDensityNearPoint\n",
    "getNearnessThreshold<-function(splineAndDensityDf, maxSplineDensityDiff){\n",
    "    # Get global maximum value of spline function at any x\n",
    "    # Get global minimum of scaled density function at any x\n",
    "    # NB: x for max and min need not (and usually won't) be the same\n",
    "    # Use these values to find the maximum difference between spline\n",
    "    # and scaled density y values (regardless of x), then define \n",
    "    # \"near\" to be when spline and scaled density y values for same x get within \n",
    "    # the specified arbitrary fraction of that difference.\n",
    "    maxSplineY = max(splineAndDensityDf$splineY) \n",
    "    minDensityY = min(splineAndDensityDf$densityY)\n",
    "    maxDiff = maxSplineY - minDensityY\n",
    "    result = maxDiff * maxSplineDensityDiff\n",
    "    return(result)\n",
    "}\n",
    "\n",
    "\n",
    "# general concept: find the leftmost point (greater than the global minimum allowed) \n",
    "# in the count distribution where the scaled density curve and the spline curve are \n",
    "# within the global arbitrary threshold of one another.  \n",
    "# This gives worse results than findSmallestMinLeftOfMax on \"good\" count distributions,\n",
    "# so it isn't the first-choice approach, but it makes a good fall-back for count\n",
    "# distributions (especially noisy or low-signal ones) where findSmallestMinLeftOfMax\n",
    "# fails to find a threshold.  Fails to find a threshold ONLY in cases where\n",
    "# spline and density curve never get \"near\" each other over range of \n",
    "# counts in the underlying count distribution.\n",
    "findSplineAndDensityNearPoint<-function(scaledDensityXandY, splineXandY, minCountLimit, \n",
    "    maxFractionAcceptableSplineDensityDiff, hist, maxCountFractionExcluded){\n",
    "    \n",
    "    log2minCountLimit = log2(minCountLimit)\n",
    "    maxSplineDensityDiff = maxFractionAcceptableSplineDensityDiff\n",
    "    result = NULL # assume failure  \n",
    "    \n",
    "    splineAndDensityDf = makeSplineAndDensityDf(scaledDensityXandY, splineXandY)\n",
    "    nearnessThreshold = getNearnessThreshold(splineAndDensityDf, maxSplineDensityDiff)\n",
    "\n",
    "    # if there are no records whose x positions are gte the global minimum allowed,\n",
    "    # give up; otherwise\n",
    "    eligibleSplineAndDensityDf = splineAndDensityDf[which(\n",
    "        splineAndDensityDf$x >= log2minCountLimit), ]\n",
    "    if (nrow(eligibleSplineAndDensityDf)>0){\n",
    "        \n",
    "        # Walk through all eligible x positions, from smallest toward largest.\n",
    "        # Assuming you don't get lucky and just find an x value right on the threshold,\n",
    "        # find the pair of x positions (if any such exist) that bracket the \n",
    "        # spot where the spline and density curves get \"near enough\" to each other.\n",
    "        # Return the point half-way between these two x positions (note that this is\n",
    "        # obviously a punt--I *could* do numerical approximation to find it, or \n",
    "        # set up a function that reached zero when the spline and density were\n",
    "        # \"near enough\" and then optimize it, but frankly it just doesn't seem \n",
    "        # worth the trouble ...)\n",
    "        putativeResult = NULL\n",
    "        largestXgtThresh = NULL\n",
    "        smallestXltThresh = NULL\n",
    "        for (i in 1:nrow(eligibleSplineAndDensityDf)){\n",
    "            currYval = eligibleSplineAndDensityDf$y[i]\n",
    "            currXval = eligibleSplineAndDensityDf$x[i]\n",
    "            if (currYval == nearnessThreshold) {\n",
    "                putativeResult = currXval\n",
    "                break\n",
    "            } else if (currYval <= nearnessThreshold) {\n",
    "                smallestLtThresh = currXval\n",
    "                if (is.null(largestXgtThresh)) {\n",
    "                    putativeResult = smallestLtThresh\n",
    "                } else {\n",
    "                    putativeResult = (smallestLtThresh - largestXgtThresh)/2 + largestXgtThresh\n",
    "                }\n",
    "                break\n",
    "            } else { # (currYval > nearnessThreshold) \n",
    "                largestXgtThresh = currXval\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        if (extremumIsAcceptable(putativeResult, hist, maxCountFractionExcluded)){\n",
    "            result = putativeResult\n",
    "        }           \n",
    "    }    \n",
    "    \n",
    "    return(result)\n",
    "}\n",
    "        \n",
    "analyzeCountsDist<-function(log2countsDfForSingleSample, rangeObj, minCountLimit, maxCountFractionExcluded,\n",
    "    maxFractionAcceptableSplineDensityDiff){\n",
    "    \n",
    "    resultSummary = \"No acceptable threshold found.\" # assume failure\n",
    "    rge<-rangeObj\n",
    "    increment = 0.05\n",
    "\n",
    "    log2CurrCountsHist<-hist(log2countsDfForSingleSample,\n",
    "        breaks=seq(0-increment,rge[2]+increment,by=increment),\n",
    "        plot=FALSE)        \n",
    "\n",
    "    # density curve\n",
    "    scaleFactor = sum(log2CurrCountsHist$counts)*increment\n",
    "    log2CurrCountsDensity<-density(log2countsDfForSingleSample)\n",
    "    scaledLog2CurrCountsDensityDf = data.frame(x=log2CurrCountsDensity$x, \n",
    "        y=log2CurrCountsDensity$y*scaleFactor)\n",
    "\n",
    "    # smoothing spline curve of non-zero freqs only\n",
    "    log2CurrCountsHistXandY = data.frame(x=log2CurrCountsHist$mids, y=log2CurrCountsHist$count)\n",
    "    nonZeroLog2CurrCountsHistXandY = log2CurrCountsHistXandY[which(log2CurrCountsHistXandY$y>0), ]    \n",
    "    log2CurrCountsSpline = smooth.spline(nonZeroLog2CurrCountsHistXandY$x, nonZeroLog2CurrCountsHistXandY$y)\n",
    "\n",
    "    # threshold selection\n",
    "    putativeThreshold = findSmallestMinLeftOfMax(log2CurrCountsSpline, minCountLimit, \n",
    "        log2CurrCountsHist, maxCountFractionExcluded)\n",
    "    if (!is.null(putativeThreshold)){\n",
    "        resultSummary = \"Smallest-local-minimum-in-valley method used.\"\n",
    "    } else {\n",
    "        putativeThreshold = findSplineAndDensityNearPoint(scaledLog2CurrCountsDensityDf, log2CurrCountsSpline,\n",
    "            minCountLimit, maxFractionAcceptableSplineDensityDiff, log2CurrCountsHist, maxCountFractionExcluded)\n",
    "        if (!is.null(putativeThreshold)){\n",
    "            resultSummary = \"Near-point-of-spline-and-density method used.\"\n",
    "        }\n",
    "    }    \n",
    "    \n",
    "    result = list(threshold = putativeThreshold, resultSummary=resultSummary,\n",
    "                  histogram=log2CurrCountsHist,\n",
    "                  scaledDensity=scaledLog2CurrCountsDensityDf, spline=log2CurrCountsSpline)\n",
    "    return(result)\n",
    "}\n",
    "\n",
    "drawAnalyzedCountsDist<-function(sampleName, rangeObj, analysisResult, manualThreshold=NULL){\n",
    "    rge<-rangeObj\n",
    "    xPositions = seq(from = 0, to = ceiling(rge[2])+1, by = 1)\n",
    "    xLabels = 2^(xPositions)\n",
    "    titleText = paste0(sampleName,\"\\n\", analysisResult$resultSummary)\n",
    "\n",
    "    hist = analysisResult$histogram\n",
    "    plot(hist, \n",
    "        col=gHistogramColor,\n",
    "        border=FALSE,\n",
    "        main=titleText,\n",
    "        xaxt = 'n', \n",
    "        xlab=\"\"\n",
    "        )        \n",
    "\n",
    "    axis(side = 1, at = xPositions, labels=xLabels, las=2)\n",
    "    mtext(\"counts (pseudocount added to zeros only)\", side=1, line=3)\n",
    "    \n",
    "    # density curve\n",
    "    lines(analysisResult$scaledDensity,col=gDensityColor)\n",
    "\n",
    "    # smoothing spline curve of non-zero freqs only\n",
    "    lines(analysisResult$spline, col=gSplineColor)\n",
    "\n",
    "    # rug plot of manual threshold, if any\n",
    "    if (!is.null(manualThreshold)){\n",
    "        rug(manualThreshold, col=gManualColor, lwd=3)    \n",
    "    }\n",
    "\n",
    "    # vertical line of selected threshold, if any\n",
    "    analysisThreshold = analysisResult$threshold\n",
    "    if (!is.null(analysisThreshold)){\n",
    "        abline(v=analysisThreshold, col=gChosenColor) \n",
    "        fractionExcludedCounts = getFractionCountsExcluded(analysisResult$histogram, \n",
    "            analysisThreshold, maxCountFractionExcluded)\n",
    "        percentExcludedCounts = fractionExcludedCounts*100          \n",
    "        title(sub=paste0(format(round(percentExcludedCounts, 1), nsmall = 1), \"% of counts excluded\"))  \n",
    "    }\n",
    "}\n",
    "\n",
    "analyzeAndDrawCountsDists<-function(multiSampleCountsDf, minCountLimit, maxCountFractionExcluded, \n",
    "                                    maxFractionAcceptableSplineDensityDiff, manualThresholds=NULL){\n",
    "    \n",
    "    resultDf = data.frame(sampleName = character(0), log2CountsThresh = numeric(0));\n",
    "    \n",
    "    multiSampleCountsDf[multiSampleCountsDf==0]<-1 #pseudocounts\n",
    "    log2MultiSampleCountsDf = log2(multiSampleCountsDf)\n",
    "    rangeObj = range(log2MultiSampleCountsDf) \n",
    "    \n",
    "    for (i in 1:ncol(multiSampleCountsDf)) {\n",
    "        currSampleName = colnames(multiSampleCountsDf)[i]\n",
    "        log2countsDfForSingleSample = log2MultiSampleCountsDf[, i]\n",
    "        analysisResult = analyzeCountsDist(log2countsDfForSingleSample, rangeObj, \n",
    "            minCountLimit, maxCountFractionExcluded, maxFractionAcceptableSplineDensityDiff)\n",
    "        resultDf = rbind(resultDf, data.frame(sampleName=currSampleName, log2CountsThresh=analysisResult$threshold))\n",
    "        \n",
    "\n",
    "        currManualThreshold = NULL\n",
    "        if (!is.null(manualThresholds)){\n",
    "            if (length(manualThresholds)>=i){\n",
    "                currManualThreshold = log2(manualThresholds[i]) \n",
    "            }\n",
    "        }           \n",
    "        \n",
    "        drawAnalyzedCountsDist(currSampleName, rangeObj, analysisResult, currManualThreshold)\n",
    "    }\n",
    "    \n",
    "    return(resultDf)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "gThresholdsDf = analyzeAndDrawCountsDists(gPreppedCountsDf, gMinCountLimit, gMaxFractionCountsExcluded, \n",
    "                                  gMaxFractionAcceptableSplineDensityDiff) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%R gThresholdsDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ccbbucsd.malicrispr.scoring_prep as ns_prep\n",
    "print(inspect.getsource(ns_prep.get_sample_name_header))\n",
    "print(inspect.getsource(ns_prep.get_abundance_thresh_header))\n",
    "print(inspect.getsource(ns_prep.get_abundance_thresh_file_suffix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_thresholds_file(thresholds_df, run_prefix, output_dir):  \n",
    "    thresholds_df.columns = [ns_prep.get_sample_name_header(), ns_prep.get_abundance_thresh_header()]\n",
    "    output_fp = ns_files.build_multipart_fp(output_dir, [run_prefix, ns_prep.get_abundance_thresh_file_suffix()])\n",
    "    \n",
    "    try:  \n",
    "        thresholds_df.to_csv(output_fp, index=False, sep='\\t')\n",
    "    except AttributeError: # if there is no to_csv method\n",
    "        thresholds_df.to_csvfile(output_fp, row_names=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "write_thresholds_file(gR['gThresholdsDf'], g_thresholds_run_prefix, g_thresholds_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
