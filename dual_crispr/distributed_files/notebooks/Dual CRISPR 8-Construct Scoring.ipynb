{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dual CRISPR Screen Analysis\n",
    "# Step 8: Construct Scoring\n",
    "\n",
    "Roman Sasik, CCBB, UCSD (rsasik@ucsd.edu)\n",
    "\n",
    "Amanda Birmingham, CCBB, UCSD (abirmingham@ucsd.edu)\n",
    "\n",
    "## Instructions\n",
    "\n",
    "To run this notebook reproducibly, follow these steps:\n",
    "1. Click **Kernel** > **Restart & Clear Output**\n",
    "2. When prompted, click the red **Restart & clear all outputs** button\n",
    "3. Fill in the values for your analysis for each of the variables in the [Input Parameters](#Input-Parameters) section\n",
    "4. Click **Cell** > **Run All**\n",
    "\n",
    "**Note**: All file outputs will be stored into the directory in which this notebook resides.\n",
    "\n",
    "## Input Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# IMPORTANT!  IMPORTANT! IMPORTANT!\n",
    "# ---------------------------------\n",
    "# Change below value to False if running on real data! Should be set to *True* ONLY when testing!\n",
    "g_use_seed = True # TODO: This should be *False* when running on real data!\n",
    "# Change below value to 1000 if running on real data! Should be set to *2* ONLY when testing!\n",
    "g_num_iterations = 2 # TODO: This should be *1000* when running on real data!\n",
    "# ---------------------------------\n",
    "\n",
    "# Required format for counts file:  Count file must be a tab-delimited \n",
    "# text file containing one row for each construct in library.  File must have\n",
    "# a header line (although count column names will be ignored) and must contain\n",
    "# the following columns in this order; 2-5 must have the specified names:\n",
    "# 1: construct id (NB: this column is expected but not currently used)\n",
    "# 2: probe_a_id\n",
    "# 3: probe_b_id\n",
    "# 4: target_a_id\n",
    "# 5: target_b_id\n",
    "# subsequent: one column for counts of the construct in question at each \n",
    "# timepoint-by-replicate combination (e.g., day 3 replicate 1).  These must \n",
    "# be ordered by timepoint and then by replicate (e.g., day 3 replicate 1, \n",
    "# day 3 replicate 2, day 14 replicate 1, day 14 replicate 2, etc).\n",
    "# The number of timepoints represented must match the number given in the\n",
    "# g_day_timepoints_str variable below.  The number of replicates is assumed\n",
    "# to be two.\n",
    "# Note that there MUST NOT be data for more than one screen in the same file,\n",
    "# as code doesn't check screen identity of columns bc assumes are from same screen (e.g., say, A549CV4)\n",
    "g_prepped_counts_run_prefix = \"tempCV4_20170314220435\"\n",
    "g_prepped_counts_dir = ('/Users/Birmingham/Work/Repositories/ccbb_tickets_2017/mali-dual-crispr-pipeline/src/python/'\n",
    "    'test_files')\n",
    "g_day_timepoints_str = \"21,28\"\n",
    "g_dataset_name = \"A549_CV4_3-14-21-28_NA_combined_simple-null-w-lfdr\"\n",
    "g_thresholds_run_prefix = \"tempCV4_method2_20170314220435\"\n",
    "g_thresholds_dir = ('/Users/Birmingham/Work/Repositories/ccbb_tickets_2017/mali-dual-crispr-pipeline/src/python/'\n",
    "    'test_files')\n",
    "g_scoring_dir = ('/Users/Birmingham/Work/Repositories/ccbb_tickets_2017/mali-dual-crispr-pipeline/src/python/'\n",
    "    'test_files/test_outputs/notebook8_tempCV4_20170314220435')\n",
    "\n",
    "g_code_location = '/Users/Birmingham/Work/Repositories/ccbb_tickets_2017/mali-dual-crispr-pipeline/src/python/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automated Set-Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import inspect\n",
    "import sys\n",
    "sys.path.append(g_code_location)\n",
    "\n",
    "import ccbbucsd.utilities.analysis_run_prefixes as ns_runs\n",
    "import ccbbucsd.utilities.files_and_paths as ns_files\n",
    "import ccbbucsd.utilities.notebook_logging as ns_logs\n",
    "\n",
    "\n",
    "def describe_var_list(input_var_name_list):\n",
    "    description_list =  [\"{0}: {1}\\n\".format(name, eval(name)) for name in input_var_name_list]\n",
    "    return \"\".join(description_list)\n",
    "\n",
    "\n",
    "ns_logs.set_stdout_info_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ns_files.verify_or_make_dir(g_scoring_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abundance Thresholds Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ccbbucsd.malicrispr.scoring_prep as ns_prep\n",
    "print(inspect.getsource(ns_prep.get_abundance_thresh_file_suffix))\n",
    "print(inspect.getsource(ns_prep.get_sample_name_header))\n",
    "print(inspect.getsource(ns_prep.get_prepped_file_suffix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "def get_abundance_thresholds_df(thresholds_dir, thresholds_run_prefix):\n",
    "    thresholds_suffix = ns_prep.get_abundance_thresh_file_suffix()\n",
    "    thresholds_fp = ns_files.build_multipart_fp(thresholds_dir, [thresholds_run_prefix, thresholds_suffix])       \n",
    "    result = pandas.read_table(thresholds_fp, index_col=ns_prep.get_sample_name_header())    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g_abundance_threshs_df = get_abundance_thresholds_df(g_thresholds_dir, g_thresholds_run_prefix)\n",
    "g_abundance_threshs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g_counts_fp = ns_files.build_multipart_fp(g_prepped_counts_dir, \n",
    "                                          [g_prepped_counts_run_prefix, ns_prep.get_prepped_file_suffix()])  \n",
    "g_counts_fp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R Magic Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Transfer from Python to R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from rpy2.robjects import r\n",
    "import rpy2.robjects as robjects\n",
    "\n",
    "gR = robjects.r\n",
    "# 'temp' assignments suppress printing of cruft stdout\n",
    "temp = gR.assign('input_filename', g_counts_fp)\n",
    "temp = gR.assign('g_time_str', g_day_timepoints_str)\n",
    "temp = gR.assign('project', g_dataset_name)\n",
    "temp = gR.assign('gUseSeed', g_use_seed)\n",
    "temp = gR.assign('niter', g_num_iterations)\n",
    "temp = gR.assign('gAbundanceThreshsDf', g_abundance_threshs_df)\n",
    "temp = gR.assign('gScoringDir', g_scoring_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    " \n",
    "commaSepStringToNumVector<-function(commaSepString){\n",
    "    strVector = unlist(strsplit(commaSepString, \",\", fixed=TRUE))\n",
    "    return(as.numeric(strVector))\n",
    "}\n",
    "\n",
    "time = commaSepStringToNumVector(g_time_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shared R Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "library(qvalue)\n",
    "\n",
    "Var<-function(x) mean(x^2)-mean(x)^2 #scalar version\n",
    "vVar<-function(x) apply(x^2,1,mean)-apply(x,1,mean)^2 #vector version\n",
    "\n",
    "Cov<-function(x,y) mean(x*y)-mean(x)*mean(y)\n",
    "vCov<-function(x,y) apply(t(x)*y,2,mean)-apply(x,1,mean)*mean(y) #x is a matrix and y is a vector\n",
    "\n",
    "sqrtsum<-function(y) sqrt(sum(y^2))\n",
    "    \n",
    "\n",
    "# x1 is log2 frequencies for the 1st replicate of all timepts\n",
    "# x2 is log2 frequencies for the 2nd replicate of all timepts\n",
    "# ab1 is abundance thresholds for all 1st replicates\n",
    "# ab2 is abundance thresholds for all 2nd replicates\n",
    "fit_ac_fc<-function(x1,ab1,x2,ab2) { #badx is TRUE when x-value is bad\n",
    "\n",
    "   er_ac<-1\n",
    "   l<-0\n",
    "   nx<-nrow(x1)\n",
    "    \n",
    "\n",
    "   good1<-t(t(x1)>ab1) # constructs as rows, timept for 1st replicates ONLY as cols, cell values are 0/FALSE, 1/TRUE for whether log2 freq for row/col combination is above relevant abundance threshold\n",
    "   good2<-t(t(x2)>ab2) # constructs as rows, timept for 2nd replicates ONLY as cols, cell values are 0/FALSE, 1/TRUE for whether log2 freq for row/col combination is above relevant abundance threshold\n",
    "   useless1<-apply(good1,1,sum)<2 # 1 = sum over rows--i.e., constructs.  Any construct that isn't above abundance threshold in 1st replicate in at least 2 timepoints has 1/TRUE in \"useless\" matrix\n",
    "   useless2<-apply(good2,1,sum)<2\n",
    "    \n",
    "    # For each constructs that isn't above abundance thresholds in at least two timepoints for this replicate, this sets that construct's \"good\" values to FALSE for *all* timepoints in this replicate\n",
    "   good1[useless1,]<-FALSE #remove singletons\n",
    "   good2[useless2,]<-FALSE #remove singletons\n",
    "   \n",
    "    # Note: here apply(goodX,1,sum) is NOT uselessX because goodX was changed above\n",
    "    #allbad is true for all the constructs that lack at least 2 acceptable-abundance timepoints in BOTH experiments\n",
    "   allbad<-apply(good1,1,sum)<2 & apply(good2,1,sum)<2 #in this case I have nothing to use in either experiment\n",
    "\n",
    "    # nt = number of timepoints\n",
    "   lambda1<-rep(0,nt)\n",
    "   lambda2<-rep(0,nt)\n",
    "   ac1<-x1[,1] #just a guess # log2 frequencies for all constructs for first timepoint in this replicate\n",
    "   ac2<-x2[,1] #just a guess\n",
    "   fc<-rep(0,nx) # nx = number of constructs\n",
    "\n",
    "    # for 1 to number of constructs\n",
    "   for (i in 1:nx) {\n",
    "       # if this construct doesn't have at least two timepoints above abundance threshold in at least one replicate, ignore it and move on\n",
    "      if (allbad[i]) next #from now on there is at least one good experiment\n",
    "          \n",
    "    # apparently \"f\" stands for fitness--which is covariance (see below)--and # stands for replicate\n",
    "    # v stands for variance and # \" \"\n",
    "      f1<-0\n",
    "      f2<-0\n",
    "      v1<-0\n",
    "      v2<-0\n",
    "          \n",
    "      g1<-good1[i,] # g1 = true/false values of whether construct i passes various abundance filters for all timepoints for the first replicate \n",
    "      if (sum(g1)>1) { #it's a good experiment # if there are at least two good timepoints for this construct in replicate 1\n",
    "         mx1<-mean(x1[i,g1]) # get the mean of the log2 frequencies for all the good timepoints for this construct in replicate 1\n",
    "          # time is GLOBAL vector of timepoints (numbers, usually in days, in ascending order)\n",
    "         mt1<-mean(time[g1]) # get mean of timepoints (e.g. mean number of days) for all the good timepoints for this construct in replicate 1\n",
    "         v1<-Var(time[g1]) # get variance of timepoints \" \"\n",
    "         f1<-Cov(x1[i,g1],time[g1]) # f1 = covariance of log2 frequencies for all the good timepoints for this construct in replicate 1 with the timepoints for those good timepoints\n",
    "      }\n",
    "          \n",
    "      # do the exact same thing as above, but for replicate 2\n",
    "      g2<-good2[i,]\n",
    "      if (sum(g2)>1) { #it's a good experiment\n",
    "         mx2<-mean(x2[i,g2])\n",
    "         mt2<-mean(time[g2])\n",
    "         v2<-Var(time[g2])\n",
    "         f2<-Cov(x2[i,g2],time[g2])\n",
    "      }\n",
    "      \n",
    "    # fc[i] is the combined fitness (across replicates) for construct i\n",
    "      fc[i]<-(f1+f2)/(v1+v2) #the combined fitness from replicate 1+2\n",
    "      #fc remains defined up to an additive constant\n",
    "\n",
    "      if (sum(g1)>1) { # if there are at least two good timepoints for this construct in replicate 1\n",
    "          # ac1 = mean of log2 freqs for this construct for good timepoints for rep 1 - (mean of timepts for good timepoints for this construct for rep 1)*combined fitness across replicates for this construct\n",
    "         ac1[i]<-mx1-fc[i]*mt1\n",
    "      }\n",
    "    \n",
    "    # same as above but for replicate 2\n",
    "      if (sum(g2)>1) {\n",
    "         ac2[i]<-mx2-fc[i]*mt2\n",
    "      }\n",
    "   }\n",
    "    \n",
    "    # ac is the initial condition (in log2 frequency) for construct c \n",
    "    # this is normalizing ac1:\n",
    "    # Roman's methods say \"By definition, log2 relative frequencies satisfy the constraint\n",
    "    # sum over c of (2^xc) = 1 at all times\"\n",
    "    # ac1 is the set of log2 frequencies for all constructs in replicate 1 at \"initial conditions\", so \n",
    "    # ac1 must satisfy the above constraint.  IFF the above constraint is satisfied, -log2(1) = 0.\n",
    "    # If the above constraint isn't satisfied, the value of -log2(sum over c of (2^ac)) is subtracted from\n",
    "    # ac to ensure the constraint is satisfied.\n",
    "   alpha<- -log2(sum(2^ac1)) \n",
    "   ac1<-ac1+alpha #enforce normalization at time=0, sum(2^ac)=1\n",
    "       \n",
    "    # same as above but for replicate 2\n",
    "   alpha<- -log2(sum(2^ac2))\n",
    "   ac2<-ac2+alpha #enforce normalization at time=0, sum(2^ac)=1\n",
    "\n",
    "    # ok, the *expected* log2 frequency for construct x at time t is:\n",
    "    # xc(t) = ac + fc*t - log2(sum over c of 2^(ac + fc*t))\n",
    "    # The below code calls the term starting with \"-log2\" \"lambda\".\n",
    "    # Note that lambda is being calculated separately for each combination of timepoint+replicate\n",
    "       \n",
    "    # for 1 to number of timepoints\n",
    "   for (i in 1:nt) {\n",
    "      lambda1[i]<- -log2(sum(2^(ac1+fc*time[i])))\n",
    "      lambda2[i]<- -log2(sum(2^(ac2+fc*time[i])))\n",
    "   } #these are initial estimates of lambda(t)\n",
    "\n",
    "    # x1 is log2 frequencies for the 1st replicate of all timepts\n",
    "   xfit1<-x1 #for size # I think this means that xfitX is being set to xX not because we're using *any* of the\n",
    "    # xX values but just to initialize xfitX to the desired size (which is the same as the size of xX)\n",
    "    \n",
    "    # for 1 to number of timepoints\n",
    "   for (j in 1:nt) {\n",
    "       # the expected value of xc(t) at this timepoint t, calculated as a column for all constructs c\n",
    "      xfit1[,j]<-ac1+fc*time[j]+lambda1[j]\n",
    "   }\n",
    "       \n",
    "    # same as above but for replicate 2\n",
    "   xfit2<-x2 #for size\n",
    "   for (j in 1:nt) {\n",
    "      xfit2[,j]<-ac2+fc*time[j]+lambda2[j]\n",
    "   }\n",
    "\n",
    "       \n",
    "   sdfc<-rep(0.1,nx) #standard error of fc\n",
    "   tstat<-rep(0,nx) # presumably t statistic\n",
    "   df<-rep(0,nx) # df = vector w one entry for each construct, with value from 0 to -2; 0 if both replicates of relevant construct are good, -1 if just one is, -2 if neither are.  Inits to 0 for all\n",
    "   p_t<-rep(1,nx) # p value from t test ... initialize to 1 (not significant) for everything\n",
    "       \n",
    "    # for 1 to number of constructs\n",
    "   for (i in 1:nx) {\n",
    "       # if this construct doesn't have enough \"good\" measurements, skip it\n",
    "      if (allbad[i]) next\n",
    "      \n",
    "        \n",
    "      g1<-good1[i,] # g1 = true/false values of whether construct i passes various abundance filters for all timepoints for the first replicate \n",
    "      g2<-good2[i,]\n",
    "    \n",
    "        # df = vector w one entry for each construct, with value from 0 to -2; 0 if both replicates of relevant construct are good, -1 if just one is, -2 if neither are\n",
    "        # I suspect that \"df\" is \"degrees of freedom\" for each construct\n",
    "      df[i]<-sum(g1)+sum(g2)-2\n",
    "          \n",
    "        # sqrtsum<-function(y) sqrt(sum(y^2))\n",
    "        # outside of this function, this sdfc value is used only in the output of the construct file\n",
    "        # I think that sdfc is \"standard deviation of fc\" for each construct.\n",
    "          \n",
    "        # So, Roman says:\n",
    "        # std err of fc = sqrt of sum over t of (lower-case-epsilon for construct c, as a function of t)^2\n",
    "        # divided by sqrt of (nc - 2)*sum over t of (t^2 - (mean of t)^2)\n",
    "        # Note that lower-case-epsilon is Xc(t) - xc(t) = xX - xfitX\n",
    "        # so xfitX - xX = - lower-case-epsilon ... but since it is being squared and then square-rooted, I\n",
    "        # suppose the negation doesn't matter.\n",
    "        # nc - 2 is the number of degrees of freedom\n",
    "        # where nc = number of data points = 2*nt minus any number of points below the threshold\n",
    "        # (note the description above seems to assume 2 replicates) ... seems to me this must mean \n",
    "        # number of data points *for this construct c*, not total.\n",
    "        # nt in above is number of timepoints, as here ...\n",
    "        # Roman also says that tc [i.e., the t statistic for construct c] = fc /SE(fc)\n",
    "        # and the internet tells me that SE(x) = SD(x)/sqrt(n) ... but maybe the sqrt(n) is just the most usual\n",
    "        # sqrt of degrees of freedom, and could be something else in a more complex system.\n",
    "        # So, the value being calculated directly below is SD(x), which is why it doesn't have the\n",
    "        # nc - 2 term that is in the denominator of the SE(x) calculation (in the manuscript, Roman says that\n",
    "        # fc's sd = sqrt(nc-2)*SE(fc), where nc-2 = degrees of freedom.  Farther below, after the calculation\n",
    "        # of sdfc, we get the calculation of tc, which is fc/(sdfc/sqrt(df)), where the sdfc/sqrt(df) term \n",
    "        # is the calculation of SE(fc).\n",
    "          \n",
    "    # result is vector with one std dev of fc for each construct\n",
    "      sdfc[i]<-sqrtsum( c(xfit1[i,g1],xfit2[i,g2]) - c(x1[i,g1],x2[i,g2]) ) /\n",
    "          sqrtsum( c(time[g1],time[g2]) - mean(c(time[g1],time[g2])) )\n",
    "          \n",
    "   }\n",
    "   #find median sd\n",
    "   has_sd<-df>0\n",
    "   median_sd<-median(sdfc[has_sd])\n",
    "   sdfc[!has_sd]<-median_sd #just so it isn't 0\n",
    "   \n",
    "   # for 1 to number of constructs\n",
    "   for (i in 1:nx) {\n",
    "       # don't try to calculate t statistic and p value for any fc that doesn't have a stderr\n",
    "      if (!has_sd[i]) next\n",
    "        # calc t statistic of fc\n",
    "      tstat[i]<-fc[i]/(sdfc[i]/sqrt(df[i]))\n",
    "        # pt is R function, presumably to do t-test :)  Result must be one-tailed, hence *2\n",
    "      p_t[i]<-2*pt(-abs(tstat[i]),df=df[i]) #raw p-values from t-test\n",
    "   }\n",
    "       \n",
    "    # ok, lfdr stands for \"local fdr\", and the lfdr function comes from the qvalue bioconductor package\n",
    "    # that is installed way above.  The first input is the vector of p-values, and the second input is the\n",
    "    # estimated proportion of true null p-values, where pi0.method is \"the method for automatically choosing tuning\n",
    "    # parameter in the estimation of π0, the proportion of true null hypotheses.\"\n",
    "   lfdr_fc<-rep(1,nx) # nx = number of constructs; default value of lfdr is set to one for all of them\n",
    "   l<-lfdr(p_t[has_sd],pi0.method=\"bootstrap\")\n",
    "   lfdr_fc[has_sd]<-l # for constructs that have an sd, the lfdr of the fc could be calculated and is now set\n",
    "       # to its calculated vale instead of the default\n",
    "\n",
    "    # ac1 is the initial condition (in log2 frequency) for each construct c for replicate 1\n",
    "    # ac2 is the initial condition (in log2 frequency) for each construct c for replicate 2\n",
    "    # fc is the fitness of each construct c (calculated across both replicates)\n",
    "    # sdfc is the std deviation of the fitness of each construct c (calculated across both replicates)\n",
    "    # p_t is the raw p value of the fc of each construct c (calculated across both replicates)\n",
    "    # lfdr_fc is the local FDR of each construct (calculated across both replicates)\n",
    "    # df is the degrees of freedom of each construct c (calculated across both replicates)\n",
    "    # allbad is a boolean value for each construct c that is true for all the constructs that lack at least 2 acceptable-abundance timepoints in BOTH experiments\n",
    "   vl<-list(ac1,ac2,fc,sdfc,p_t,lfdr_fc,df,allbad)\n",
    "   return(vl)\n",
    "}\n",
    "\n",
    "plot_fit<-function(x1,ac1,fc1,ab1,x2,ac2,fc2,ab2,minfc=0.10) {\n",
    "\n",
    "   nx<-nrow(x1)\n",
    "   maxt<-time[nt]+3\n",
    "   plot_lambda1<-rep(0,maxt)\n",
    "   plot_lambda2<-rep(0,maxt)\n",
    "\n",
    "    # TODO: Do these 1, 2 represent hardcoding of # of expected replicates?  If so, need to refactor function\n",
    "   good1<-t(t(x1)>ab1)\n",
    "   good2<-t(t(x2)>ab2)\n",
    "   allbad<-apply(good1,1,sum)<2 & apply(good2,1,sum)<2 #in this case I have nothing to use in either experiment\n",
    "\n",
    "   for (i in 1:maxt) plot_lambda1[i]<- -log2(sum(2^(ac1+fc1*i)))\n",
    "   for (i in 1:maxt) plot_lambda2[i]<- -log2(sum(2^(ac2+fc2*i)))\n",
    "   \n",
    "   rge<-range(c(x1,x2))\n",
    "   for (i in 1:nx) {\n",
    "      if (allbad[i]) next\n",
    "      if (abs(fc1[i])<minfc & abs(fc2[i])<minfc) next\n",
    "      pch<-rep(1,nt)\n",
    "      pch[good1[i,]]<-16 #circle\n",
    "      plot(time,x1[i,],ylim=rge,pch=pch,cex=1.2,main=pA_pB[i],xlab=\"time\",ylab=expression(paste(log[2],\" relative frequency\")))\n",
    "      yfit<-ac1[i]+fc1[i]*(1:maxt)+plot_lambda1\n",
    "      lines(1:maxt,yfit)\n",
    "\n",
    "      pch<-rep(1,nt)\n",
    "      pch[good2[i,]]<-16 \n",
    "      points(time,x2[i,],pch=pch,cex=1.2,col=\"blue\")\n",
    "      yfit<-ac2[i]+fc2[i]*(1:maxt)+plot_lambda2\n",
    "      lines(1:maxt,yfit,col=\"blue\")\n",
    "   }\n",
    "}\n",
    "\n",
    "#iterative robust least squares\n",
    "# fc is a symmetric probe-by-probe matrix where the value in each cell is the fc value for the construct including\n",
    "# those two probes, or zero if there is no construct for that probe-by-probe combination.\n",
    "# w0 is a symmetric probe-by-probe matrix of initial weights, where the value in each cell is zero for \"bad\"\n",
    "# and/or non-existent constructs and one for \"good\" constructs.\n",
    "# The manuscript gives eqn 2 as:\n",
    "# fc = fp + fp' + pi sub pp'\n",
    "# and states \"The probe fitnesses are found by robust fitting of Eq. (2). \n",
    "# The probe-level pi-scores are the residuals of the robust fit.\"\n",
    "irls<-function(fc,w0,probes,ag=2,tol=1e-3,maxiter=30) {\n",
    "# w0 is the physical goodness of constructs. It is not subject to change. # ab: what is \"physical goodness\"??\n",
    "# It is used to modify w, to silence bad constructs \n",
    "\n",
    "    # upper.tri seems to be getting the upper triangle of the symmetric probe-by-probe fc matrix\n",
    "   expressed_utri<-upper.tri(fc) & w0>0\n",
    "   n<-dim(fc)[1] # lessee--that would be number of probes; note that n here is *different* than n outside the scope of this function, where it is the number of genes :(\n",
    "   w<-matrix(1,nrow=n,ncol=n) #initial weights # ab: probe-by-probe matrix with default values of 1 everywhere except on diagonal, where they are zero\n",
    "   diag(w)<-0\n",
    "    # errr.  what are e and f?\n",
    "   fij<-matrix(0,nrow=n,ncol=n) #initial weights\n",
    "   eij<-matrix(0,nrow=n,ncol=n) #initial weights\n",
    "   b<-rep(0,n) #rhs #ab: wth is rhs?\n",
    "\n",
    "   #iteration step 0\n",
    "   w<-w*w0 # I think here we are \"silenc[ing] bad constructs\", which have w0 = 0\n",
    "   A<-w\n",
    "   for (i in 1:n) { # for each probe\n",
    "      b[i]<-sum(fc[,i]*w[,i]) # sum of fc*weight for all probes paired with this probe.  Why set i as the second index into in the probe-by-probe matrix rather than the first?  Isn't the matrix symmetric?\n",
    "      A[i,i]<-sum(w[,i])+small # reminder: small<-1e-6 ; it is a parameter hardcoded at the top of the whole notebook.\n",
    "        # so, A = w and w is 1 everywhere except on the diagonal and at probe-by-probe pairs where the analogous \n",
    "        # construct is either bad or non-existent.  This seems to be setting the values along the diagonal to the\n",
    "        # sum of the weights for that probe (across all other probes it is paired with) plus a tiny value, presumably\n",
    "        # to make sure the diagonal is now *never* zero.\n",
    "   }\n",
    "    \n",
    "    # apparently, \"solve() function solves equation a %*% x = b for x, where b is a vector or matrix.\" (from http://www.endmemo.com/program/R/solve.php)\n",
    "    # Note that %*% is apparently R notation for \"multiply matrices\".  Ok, so figure out what matrix you need to multiply A by to get b,\n",
    "    # and call that matrix y (again, note y here is *different* from y outside this function, where it is #log2 frequencies :( )\n",
    "    # Here, y is a matrix with 1 column and as many rows as there are probes, since b is an array (essentially, a matrix with 1 row and as many columns as there are probes)\n",
    "   y<-solve(A,b)\n",
    "   names(y)<-probes\n",
    "    # ok, here's that same logic for getting all pairs of probes\n",
    "   for (i in 1:(n-1)) {\n",
    "      for (j in (i+1):n) {\n",
    "         fij[i,j]<-y[i]+y[j]\n",
    "      }\n",
    "   }\n",
    "   fij<-fij+t(fij) # make fij symmetric\n",
    "   eij<-fc-fij #residuals\n",
    "    # ab: end iteration step 0\n",
    "\n",
    "   l<-1 #counter\n",
    "   rel<-1 # apparently, to judge by Roman's comment at the end of this while loop, \"rel\" = \"relative error\"\n",
    "   while (rel > tol & l < maxiter) {#iterate until tol is reached or maxit\n",
    "      s<-sd(eij[expressed_utri]) #calculate sd only from expressed constructs # ab: calc stddev of residuals for all expressed probes\n",
    "      yold<-y # archive y, the matrix w/ one column and rows for each probe\n",
    "\n",
    "      w<-(1-eij^2/(ag*s)^2)^2 #something like Tukey's biweight\n",
    "      w[abs(eij)>(ag*s)]<-0\n",
    "      diag(w)<-0\n",
    "\n",
    "      w<-w*w0\n",
    "\n",
    "      A<-w\n",
    "      for (i in 1:n) {\n",
    "         b[i]<-sum(fc[,i]*w[,i])\n",
    "         A[i,i]<-sum(w[,i])+small\n",
    "      }\n",
    "      y<-solve(A,b)\n",
    "      names(y)<-probes\n",
    "      fij<-matrix(0,nrow=n,ncol=n) #initial weights\n",
    "      for (i in 1:(n-1)) {\n",
    "         for (j in (i+1):n) {\n",
    "            fij[i,j]<-y[i]+y[j]\n",
    "         }\n",
    "      }\n",
    "      fij<-fij+t(fij)\n",
    "      eij<-fc-fij #residuals\n",
    "       \n",
    "       # ok, in iteration 0, rel = one and l (the counter) = one\n",
    "       # here, the counter = the counter plus one\n",
    "       # rel: we're calculating the difference of the y value for this time through the loop\n",
    "       # from the y value the last time through the loop and then squaring it (presumably to get rid of \n",
    "       # any negatives); we do this across all probes and sum the squared values.  Then we divide that sum\n",
    "       # of squares by either one or the sum across all probes of the square of the y values from the last time \n",
    "       # through the loop, whichever is greater.  Then we take the sqrt of that ratio and say it is the \n",
    "       # \"relative error\".\n",
    "\n",
    "      rel<-sqrt(sum((y-yold)^2)/max(1,sum(yold^2))) #relative error\n",
    "       # reminder: sqrtsum<-function(y) sqrt(sum(y^2))\n",
    "      cat(l,sqrtsum(yold),sqrtsum(y-yold),\"\\n\") # print out some values to the screen\n",
    "      l<-l+1\n",
    "       \n",
    "       # we break out of this loop when either: \n",
    "       # a) the relative error has fallen below the \"tol\" value (what does \"tol\" stand for?) OR\n",
    "       # b) we have performed the maximum number of trips through the loop.\n",
    "       # Both tol and maxiter are parameters passed into this function.\n",
    "   }\n",
    "    # Roman's comment when y is unpacked from this returned list is \"#these are probe fitnesses fp\"\n",
    "    # Roman's comment when eij is unpacked from this returned list is \"#raw pi-scores per construct\"\n",
    "   vl<-list(y, fij, eij)\n",
    "   return(vl)\n",
    "}\n",
    "\n",
    "plotOverlappingHist <- function(a, b, colors=c(\"gray70\",\"gray20\",\"gray50\"), breaks=NULL, xlim=NULL, ylim=NULL, xlab=NULL,ylab=NULL, main=NULL){\n",
    "   ahist=NULL\n",
    "   bhist=NULL\n",
    "   if(!(is.null(breaks))){\n",
    "      ahist=hist(a,breaks=breaks,plot=FALSE)\n",
    "      bhist=hist(b,breaks=breaks,plot=FALSE)\n",
    "   } else {\n",
    "      ahist=hist(a,plot=FALSE)\n",
    "      bhist=hist(b,plot=FALSE)\n",
    "      dist = ahist$breaks[2]-ahist$breaks[1]\n",
    "      breaks = seq(min(ahist$breaks,bhist$breaks),max(ahist$breaks,bhist$breaks),dist)\n",
    "      ahist=hist(a,breaks=breaks,plot=FALSE)\n",
    "      bhist=hist(b,breaks=breaks,plot=FALSE)\n",
    "   }\n",
    " \n",
    "   if(is.null(xlim)){\n",
    "      xlim = c(min(ahist$breaks,bhist$breaks),max(ahist$breaks,bhist$breaks))\n",
    "   }\n",
    " \n",
    "   if(is.null(ylim)){\n",
    "      ylim = c(0,max(ahist$counts,bhist$counts))\n",
    "   }\n",
    " \n",
    "   overlap = ahist\n",
    "   for(i in 1:length(overlap$counts)){\n",
    "      if(ahist$counts[i] > 0 & bhist$counts[i] > 0){\n",
    "         overlap$counts[i] = min(ahist$counts[i],bhist$counts[i])\n",
    "      } else {\n",
    "         overlap$counts[i] = 0\n",
    "      }\n",
    "   }\n",
    "\n",
    "   plot(ahist, xlim=xlim, ylim=ylim, col=colors[1], border=colors[1],xlab=xlab,ylab=ylab,main=main)\n",
    "   plot(bhist, xlim=xlim, ylim=ylim, col=colors[2], border=colors[2], add=TRUE)\n",
    "   plot(overlap, xlim=xlim, ylim=ylim, col=colors[3], border=colors[3], add=TRUE)\n",
    "}\n",
    "\n",
    "plot_scatterplots<-function() {\n",
    "    #now plot fitted value scatterplots\n",
    "    \n",
    "     # TODO: need to refactor function\n",
    "    fit_x1<-matrix(0,nrow=nn,ncol=nt)\n",
    "    fit_x2<-matrix(0,nrow=nn,ncol=nt)\n",
    "    for (j in 1:nt) {\n",
    "       fit_x1[,j]<-2^(a1+fc*time[j])\n",
    "       fit_x2[,j]<-2^(a2+fc*time[j])\n",
    "    }\n",
    "    fit_x1[bad1,]<-0 #remove missing constructs\n",
    "    fit_x2[bad2,]<-0\n",
    "    ab1<-apply(fit_x1,2,sum)\n",
    "    ab2<-apply(fit_x2,2,sum)\n",
    "    fit_x1<-t(t(fit_x1)/ab1) #take ratio to get fitted x_c values\n",
    "    fit_x2<-t(t(fit_x2)/ab2)\n",
    "    fit_x1[!bad1,]<-log2(fit_x1[!bad1,])\n",
    "    fit_x2[!bad2,]<-log2(fit_x2[!bad2,])\n",
    "    fit_x1[bad1,]<-0 #remove missing constructs\n",
    "    fit_x2[bad2,]<-0\n",
    "\n",
    "     # TODO: need to refactor function\n",
    "    #plot experimental values\n",
    "    for (i in 2:nt) {\n",
    "       smoothScatter(x1[!bad1,c(1,i)],xlim=c(-17,-11),ylim=c(-17,-11),transformation = function(x) {log2(x+1)^.75},pch=16,cex=0.4,xlab=paste(\"log2 frequency, d\",time[1],sep=\"\"),ylab=paste(\"log2 frequency, d\",time[i],sep=\"\"),main=\"experimental log2 frequencies, replicate 1\")\n",
    "       abline(0,1,col=\"#000066\")\n",
    "       a<-(x1[!bad1,i]+x1[!bad1,1])/2\n",
    "       m<-(x1[!bad1,i]-x1[!bad1,1])\n",
    "       smoothScatter(a,m,xlim=c(-17,-11),ylim=c(-10,10),transformation = function(x) {log2(x+1)^.75},pch=16,cex=0.4,main=paste(\"experimental log2 frequencies, replicate 1, d\",time[1],\"-d\",time[i],sep=\"\"))\n",
    "       abline(h=0,col=\"#000066\")\n",
    "       yl<-lowess(a,m,f=0.2)\n",
    "       lines(yl,col=\"red\")\n",
    "    }\n",
    "    for (i in 2:nt) {\n",
    "       smoothScatter(x2[!bad2,c(1,i)],xlim=c(-17,-11),ylim=c(-17,-11),transformation = function(x) {log2(x+1)^.75},pch=16,cex=0.4,xlab=paste(\"log2 frequency, d\",time[1],sep=\"\"),ylab=paste(\"log2 frequency, d\",time[i],sep=\"\"),main=\"experimental log2 frequencies, replicate 2\")\n",
    "       abline(0,1,col=\"#000066\")\n",
    "       a<-(x2[!bad2,i]+x2[!bad2,1])/2\n",
    "       m<-(x2[!bad2,i]-x2[!bad2,1])\n",
    "       smoothScatter(a,m,xlim=c(-17,-11),ylim=c(-10,10),transformation = function(x) {log2(x+1)^.75},pch=16,cex=0.4,main=paste(\"experimental log2 frequencies, replicate 2, d\",time[1],\"-d\",time[i],sep=\"\"))\n",
    "       abline(h=0,col=\"#000066\")\n",
    "       yl<-lowess(a,m,f=0.2)\n",
    "       lines(yl,col=\"red\")\n",
    "    }\n",
    "\n",
    "    #now plot fitted values\n",
    "    for (i in 2:nt) {\n",
    "       smoothScatter(fit_x1[!bad1,c(1,i)],xlim=c(-17,-11),ylim=c(-17,-11),transformation = function(x) {log2(x+1)^.75},pch=16,cex=0.4,xlab=paste(\"log2 frequency, d\",time[1],sep=\"\"),ylab=paste(\"log2 frequency, d\",time[i],sep=\"\"),main=\"fitted frequencies, replicate 1\")\n",
    "       abline(0,1,col=\"#000066\")\n",
    "       a<-(fit_x1[!bad1,i]+fit_x1[!bad1,1])/2\n",
    "       m<-(fit_x1[!bad1,i]-fit_x1[!bad1,1])\n",
    "       smoothScatter(a,m,xlim=c(-17,-11),ylim=c(-10,10),transformation = function(x) {log2(x+1)^.75},pch=16,cex=0.4,main=paste(\"fitted log2 frequencies, replicate 1, d\",time[1],\"-d\",time[i],sep=\"\"))\n",
    "       abline(h=0,col=\"#000066\")\n",
    "       yl<-lowess(a,m,f=0.2)\n",
    "       lines(yl,col=\"red\")\n",
    "    }\n",
    "    for (i in 2:nt) {\n",
    "       smoothScatter(fit_x2[!bad2,c(1,i)],xlim=c(-17,-11),ylim=c(-17,-11),transformation = function(x) {log2(x+1)^.75},pch=16,cex=0.4,xlab=paste(\"log2 frequency, d\",time[1],sep=\"\"),ylab=paste(\"log2 frequency, d\",time[i],sep=\"\"),main=\"fitted frequencies, replicate 2\")\n",
    "       abline(0,1,col=\"#000066\")\n",
    "       a<-(fit_x2[!bad2,i]+fit_x2[!bad2,1])/2\n",
    "       m<-(fit_x2[!bad2,i]-fit_x2[!bad2,1])\n",
    "       smoothScatter(a,m,xlim=c(-17,-11),ylim=c(-10,10),transformation = function(x) {log2(x+1)^.75},pch=16,cex=0.4,main=paste(\"fitted log2 frequencies, replicate 1, d\",time[1],\"-d\",time[i],sep=\"\"))\n",
    "       abline(h=0,col=\"#000066\")\n",
    "       yl<-lowess(a,m,f=0.2)\n",
    "       lines(yl,col=\"red\")\n",
    "    }\n",
    "\n",
    "    #now cross-plots at times 1 2 3..\n",
    "    for (i in 1:nt) {\n",
    "       smoothScatter(x1[good,i],x2[good,i],xlim=c(-17,-11),ylim=c(-17,-11),transformation = function(x) {log2(x+1)^.75},pch=16,cex=0.4,xlab=paste(\"replicate 1, d\",time[i],sep=\"\"),ylab=paste(\"replicate 2, d\",time[i],sep=\"\"),main=paste(\"comparison of experimental replicates, d\",time[i],sep=\"\"))\n",
    "    abline(0,1,col=\"#000066\")\n",
    "    }\n",
    "    for (i in 1:nt) {\n",
    "       smoothScatter(fit_x1[good,i],fit_x2[good,i],xlim=c(-17,-11),ylim=c(-17,-11),transformation = function(x) {log2(x+1)^.75},pch=16,cex=0.4,xlab=paste(\"replicate 1, d\",time[i],sep=\"\"),ylab=paste(\"replicate 2, d\",time[i],sep=\"\"),main=paste(\"comparison of fitted replicates, d\",time[i],sep=\"\"))\n",
    "    abline(0,1,col=\"#000066\")\n",
    "    }\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counts Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%R X<-read.table(input_filename,sep=\"\\t\",header=TRUE, stringsAsFactors=FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R \n",
    "\n",
    "small<-1e-6\n",
    "nt<-length(time) #nt >= 2 # number of timepoints\n",
    "mt<-mean(time)\n",
    "vt<-Var(time)\n",
    "\n",
    "#preliminary preparations of the input data frame\n",
    "# TODO: ok, the 5 & 6 are definitely hardcoding for #s of expected info columns.\n",
    "# TODO: the 2 seems like it is hardcoding for # of replicates\n",
    "data<-data.matrix(X[,6:(5+2*nt)])\n",
    "# TODO: target_a_id and target_b_id are hardcodings for info column names; undesirable.\n",
    "# TODO: however, assuming that there will be two genes (and two probes) per construct is acceptable\n",
    "# since this is a DUAL crispr pipeline.\n",
    "ixA<-grep(\"NonTargeting\",X$target_a_id)\n",
    "X$target_a_id[ixA]=0 # nontargeting gene names set to 0\n",
    "ixB<-grep(\"NonTargeting\",X$target_b_id)\n",
    "X$target_b_id[ixB]=0 # nontargeting gene names set to 0\n",
    "\n",
    "good<-(X$target_a_id != X$target_b_id) #reject any constructs where both probes are for same gene (including both zero)\n",
    "goodX<-X[good,] #the 0-0 constructs are gone\n",
    "nn<-sum(good) #this many constructs\n",
    "\n",
    "cpA<-as.character(goodX$probe_a_id)\n",
    "# TODO: \"Nontargeting\" (throughout) is hardcoding for ntc prefix; should be refactored\n",
    "ix<-grep(\"NonTargeting\",cpA)\n",
    "cpA[ix]<-paste(\"0\",cpA[ix],sep=\"\") #this puts NonTargeting probes at the beginning of alphabetically sorted order\n",
    "\n",
    "cpB<-as.character(goodX$probe_b_id)\n",
    "ix<-grep(\"NonTargeting\",cpB)\n",
    "cpB[ix]<-paste(\"0\",cpB[ix],sep=\"\")\n",
    "\n",
    "pswitch<-cpA>cpB #need to switch?\n",
    "phold<-cpA[pswitch]\n",
    "cpA[pswitch]<-cpB[pswitch]\n",
    "cpB[pswitch]<-phold #cpA and cpB are always in alphabetical order, cpA < cpB\n",
    "probes<-sort(unique(c(cpA,cpB))) #entire probe set in alphabetical order\n",
    "nprobes<-length(probes)\n",
    "\n",
    "\n",
    "cgA<-as.character(goodX$target_a_id)\n",
    "cgB<-as.character(goodX$target_b_id)\n",
    "genes<-sort(unique(cgA)) #should be 74 \"genes\"\n",
    "n<-length(genes) # n = 74 if doing it by genes or 222 if doing it by probe # number of genes\n",
    "mm<-n*(n-1)/2\n",
    "\n",
    "gswitch<-cgA>cgB #need to switch?\n",
    "ghold<-cgA[gswitch]\n",
    "cgA[gswitch]<-cgB[gswitch]\n",
    "cgB[gswitch]<-ghold\n",
    "\n",
    "# TODO: probably separator should be specified in set-up rather than hardcoded\n",
    "gA_gB<-paste(cgA,cgB,sep=\"_\")\n",
    "pA_pB<-paste(cpA,cpB,sep=\"_\")\n",
    "goodX<-data.frame(goodX,cgA,cgB,gA_gB) #now gA_gB is ordered so that gA < gB\n",
    "\n",
    "# TODO: def refactor here, as above\n",
    "gooddata<-data.matrix(goodX[,6:(5+2*nt)])\n",
    "# TODO: are we ok with hardcoding what the pseudocount will be?  Maybe should set in params.\n",
    "gooddata[gooddata==0]<-1 #pseudocounts\n",
    "abundance<-apply(gooddata,2,sum)\n",
    "y<-t(log2(t(gooddata)/abundance)) #log2 frequencies\n",
    "#end data prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abundance Thresholds Unit Conversion\n",
    "\n",
    "The abundance thresholds that come from notebook 7 are in the units of log2 of counts, while the abundances that are used by the scoring code are in the units of log2 of count frequencies (where count frequencies are counts/total counts for a sample).  Log2 of count frequencies = log2 of counts - log2 of total counts per sample, so to get the abundance thresholds in the desired units it is only necessary to subtract log2 of total counts per sample from each of the threshold produced by notebook 7.  The total counts per sample information in the scoring code is stored in the  `abundance` vector above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "convertAbundanceThresholdsUnits <- function(totalCountsPerSample, log2CountsThresholdsPerSample){    \n",
    "    if (names(totalCountsPerSample) != rownames(log2CountsThresholdsPerSample)){\n",
    "        stop(paste0(\"Sample names for total counts per sample (\", paste(names(totalCountsPerSample), collapse=\",\"),\n",
    "                   \") do not match sample names for log2 abundance thresholds (\",\n",
    "                   paste(rownames(log2CountsThresholdsPerSample), collapse=\",\"), \").\"))\n",
    "    }\n",
    "    \n",
    "    log2CountsThresholdsVector = as.numeric(as.vector(log2CountsThresholdsPerSample[,1]))\n",
    "    names(log2CountsThresholdsVector) = rownames(log2CountsThresholdsPerSample)\n",
    "    log2CountsFreqsVector = log2CountsThresholdsVector - log2(totalCountsPerSample)\n",
    "    return(log2CountsFreqsVector)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R \n",
    "\n",
    "# ab0 is the vector of log2 frequency abundance thresholds, e.g.,\n",
    "# array([-19. , -18.5, -18.5, -19. , -19. , -19. , -19. , -19. ])\n",
    "ab0 = convertAbundanceThresholdsUnits(abundance, gAbundanceThreshsDf)\n",
    "print(ab0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Constructs Below Abundance Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R \n",
    "\n",
    "# So ... we're building 3 matrices of n genes by n genes.\n",
    "# The first one just \n",
    "# Again, here 1 & 2 hardcoding acceptable as means 1st and 2nd of DUAL crispr construct\n",
    "g1names<-matrix(\"\",ncol=n,nrow=n) # n = number of genes\n",
    "g2names<-matrix(\"\",ncol=n,nrow=n)\n",
    "ggnames<-matrix(\"\",ncol=n,nrow=n)\n",
    "for (i in 1:(n-1)) {\n",
    "   for (j in (i+1):n) {\n",
    "      g1names[i,j]<-genes[i]\n",
    "      g2names[i,j]<-genes[j]\n",
    "       # TODO: Separator should be set in params rather than hardcoded\n",
    "      ggnames[i,j]<-paste(genes[i],\"_\",genes[j],sep=\"\")\n",
    "      ggnames[j,i]<-ggnames[i,j]\n",
    "   }\n",
    "}\n",
    "# OK, everything above this comment actually has zero to do with finding the # of constructs below the\n",
    "# abundance thresholds--it is just setting up some data structures with gene labels in them for use (much) later\n",
    "# in the pi score file output.\n",
    "\n",
    "\n",
    "# y is df of log2 frequencies (rows = constructs, cols = timept+replicate, no info columns)\n",
    "# for replicate 1\n",
    "# \"2\"s here and line below look like replicate hardcoding; refactor\n",
    "\n",
    "# Ok, so this is getting the log2 frequencies for the 1st replicate of all timepts\n",
    "x1<-y[,seq(1,2*nt,by=2)]\n",
    "# This is getting the abundance thresholds for all of these 1st replicates\n",
    "ab1<-ab0[seq(1,2*nt,by=2)]\n",
    "# TODO: 1st \"2\" here is ok (designates row vs col) ... but what is source of second?\n",
    "bad1<-apply(t(x1)>ab1,2,sum)<2\n",
    "print(sum(bad1))\n",
    "\n",
    "# for replicate 2\n",
    "# \"2\"s here and line below look like replicate hardcoding; refactor\n",
    "# Ok, so this is getting the log2 frequencies for the 2nd replicate of all timepts\n",
    "x2<-y[,seq(2,2*nt,by=2)]\n",
    "# This is getting the abundance thresholds for all of these 2nd replicates\n",
    "ab2<-ab0[seq(2,2*nt,by=2)]\n",
    "# TODO: 1st \"2\" here is ok (designates row vs col); 2nd doesn't mean replicates but \n",
    "# represents arbitrary(?) decision that a construct is bad if it isn't over the relevant\n",
    "# abundance threshold in at least two timepoints.  Could one reasonably choose a \n",
    "# different value?  If so, should refactor to set in params.\n",
    "\n",
    "# 2 in apply call params means \"sum over columns\".  Because of t call, x2 has been \n",
    "# transposed so t(x2) has timept as rows and constructs as columns.\n",
    "# We're calling \"bad\" any construct that doesn't have log2 frequency values above the timepoint-specific\n",
    "# abundance threshold for at least two timepoints\n",
    "bad2<-apply(t(x2)>ab2,2,sum)<2\n",
    "print(sum(bad2))\n",
    "\n",
    "# the printed numbers are *per-replicate*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot of Posterior Probability By Construct Fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R \n",
    "\n",
    "# x1 is log2 frequencies for the 1st replicate of all timepts\n",
    "# x2 is log2 frequencies for the 2nd replicate of all timepts\n",
    "# ab1 is abundance thresholds for all 1st replicates\n",
    "# ab2 is abundance thresholds for all 2nd replicates\n",
    "# after this cell, these 4 are used again one more time considerably later--in the call to plot_fit that makes\n",
    "# Log2 Frequency vs Time Plots for Constructs with Large Fitness File Output\n",
    "\n",
    "rownames(x1)<-pA_pB \n",
    "rownames(x2)<-pA_pB\n",
    "\n",
    "\n",
    "resf<-fit_ac_fc(x1,ab1,x2,ab2)\n",
    "# I don't know what resf means ... maybe \"resulting fit\"?\n",
    "\n",
    "# TODO: 2-replicate assumption is baked into outputs of fit_ac_fc function\n",
    "a1<-resf[[1]] # a1 is the initial condition (in log2 frequency) for each construct c for replicate 1\n",
    "a2<-resf[[2]] # a2 is the initial condition (in log2 frequency) for each construct c for replicate 2\n",
    "fc<-resf[[3]] # fc is the fitness of each construct c (calculated across both replicates)\n",
    "sdfc<-resf[[4]] #standard error # Roman's comment says this is stderr, but I don't think it actually is--I think sdfc is the std deviation of the fitness of each construct c (calculated across both replicates)\n",
    "p_t<-resf[[5]] #raw p-value from t-test # p_t is the raw p value of the fc of each construct c (calculated across both replicates)\n",
    "lfdr_fc<-resf[[6]] #lfdr from p_t (Storey) # lfdr_fc is the local FDR of each construct (calculated across both replicates)\n",
    "pp_fc<-1-lfdr_fc  # ab: I believe this is posterior probability of fc of each construct c (calculated across both replicates)\n",
    "# Wikipedia: \"the posterior probability of ... an uncertain proposition is the conditional probability that is assigned after the relevant evidence ... is taken into account\".  Thus, higher equals more probable.\n",
    "df<-resf[[7]] #degrees of freedom # df is the degrees of freedom of each construct c (calculated across both replicates)\n",
    "allbad<-resf[[8]] #is TRUE when both experiments are bad (at most 1 good value) # allbad is a boolean value for each construct c that is true for all the constructs that lack at least 2 acceptable-abundance timepoints in BOTH experiments\n",
    "\n",
    "# plot fc for all good constructs vs posterior probability of fc for all those same good constructs\n",
    "plot(fc[!allbad],pp_fc[!allbad],pch=16,cex=0.2,xlab=expression(f[\"c\"]),ylab=\"posterior probability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot of Histograms of Frequency by Construct Fitness\n",
    "\n",
    "Light grey represents the full construct space, while dark grey represents only those constructs that pass the abundance thresholds chosen above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R \n",
    "\n",
    "# nn = number of *good* constructs\n",
    "# r = nn random numbers pulled from a uniform distribution with (default) min of 0 and max of 1 \n",
    "# set seed ONLY FOR TESTING\n",
    "if (gUseSeed == TRUE) {\n",
    "    set.seed(1)\n",
    "}\n",
    "r<-runif(nn) \n",
    "fr<-fc[r<pp_fc] # fc for all the constructs where the random posterior probability is less than the actual calculated posterior probability for this construct\n",
    "# thus, fr is the distribution of fcs for constructs whose true pp of happening is greater than their random pp of happening--roughly, fcs of constructs whose fc values are more likely than chance\n",
    "rge<-range(fc) # range of fcs across all constructs\n",
    "\n",
    "# TODO: what determines the 0.001 for the break sequence?  Need to set in params?\n",
    "plotOverlappingHist(fc[!allbad],fr,breaks=seq(rge[1]-.001,rge[2]+0.001,by=0.001),xlab=expression(f[\"c\"]),ylab=\"Frequency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histograms of Relative Abundance At Time Zero For Each Replicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R \n",
    "\n",
    "# assign construct names to the newly-created arrays of per construct info\n",
    "names(fc)<-pA_pB\n",
    "names(pp_fc)<-pA_pB\n",
    "names(sdfc)<-pA_pB\n",
    "# TODO: repeat of the hist 2 times is clearly for the 2 replicates and needs to be refactored.\n",
    "hist(2^a1,breaks=1000,xlab=\"relative abundance\",main=\"replicate 1, time 0\")\n",
    "hist(2^a2,breaks=1000,xlab=\"relative abundance\",main=\"replicate 2, time 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterative Robust Least Squares Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "# nn = number of *good* constructs\n",
    "# whatever u is, it is 0 for all bad and/or non-existent constructs and, at least at the beginning, one for all good constructs\n",
    "u1<-rep(0,nn)\n",
    "names(u1)<-pA_pB\n",
    "u1[!allbad]<-1  #all other weights set to 1\n",
    "\n",
    "fc0<-fc \n",
    "\n",
    "# just sets expected matrix size for all these--num probes by num probes, w/defaults of zero, and row/col names\n",
    "fc_0<-matrix(0,nrow=nprobes,ncol=nprobes)\n",
    "sdfc_0<-matrix(0,nrow=nprobes,ncol=nprobes)\n",
    "w0_0<-matrix(0,nrow=nprobes,ncol=nprobes)\n",
    "pp_0<-matrix(0,nrow=nprobes,ncol=nprobes)\n",
    "rownames(fc_0)<-probes\n",
    "colnames(fc_0)<-probes\n",
    "rownames(sdfc_0)<-probes\n",
    "colnames(sdfc_0)<-probes\n",
    "rownames(w0_0)<-probes\n",
    "colnames(w0_0)<-probes\n",
    "rownames(pp_0)<-probes\n",
    "colnames(pp_0)<-probes\n",
    "\n",
    "\n",
    "# for 1 to number of genes - 1\n",
    "for (i in 1:(n-1)) {\n",
    "    # TODO: refactor these \"3\"s (the expected number of probes per gene)\n",
    "   for (k in 1:3) {\n",
    "       # index of current probe for current gene in probes array\n",
    "      iprobe<-(i-1)*3+k\n",
    "       # probes is entire probe name set in alphabetical order\n",
    "      iprobe_name<-probes[iprobe]\n",
    "       \n",
    "\n",
    "       # for all possible second genes that come after the current first gene (i) \n",
    "      for (j in (i+1):n) {\n",
    "          # for all the constructs of the second gene\n",
    "         for (l in 1:3) {\n",
    "            jprobe<-(j-1)*3+l\n",
    "            jprobe_name<-probes[jprobe] # as for first gene, get index and then name of second gene\n",
    "             \n",
    "             #generate the construct name\n",
    "            construct<-paste(iprobe_name,\"_\",jprobe_name,sep=\"\")\n",
    "            w0_0[iprobe_name,jprobe_name]<-u1[construct] #initial weights. non-existent pairs will have w0=0.  #ab: Roman's comment here says this is initial weights, but his comment in the irls function says that this is actually the \"physical goodness\" of each construct.  Seems to be integer booleans (i.e., 1 for true, 0 for false) \n",
    "            pp_0[iprobe_name,jprobe_name]<-pp_fc[construct] #initial weights. non-existent pairs will have w0=0 # ab: I don't think this comment is right either.  pp_fc are the posterior probabilities for the fc of each construct\n",
    "            fc_0[iprobe_name,jprobe_name]<-fc0[construct]\n",
    "            sdfc_0[iprobe_name,jprobe_name]<-sdfc[construct]\n",
    "         }\n",
    "      }\n",
    "   }\n",
    "}\n",
    "w0_0<-w0_0+t(w0_0) #make symmetric\n",
    "fc_0<-fc_0+t(fc_0)\n",
    "pp_0<-pp_0+t(pp_0)\n",
    "\n",
    "#robust fitting\n",
    "# TODO: What is this 2 and do I need to worry about it?\n",
    "res2<-irls(fc_0,w0_0,probes,ag=2,tol=1e-3,maxit=50)\n",
    "\n",
    "fp<-res2[[1]] #these are probe fitnesses fp\n",
    "#since fp is determined up to an additive constant, set the constant by \n",
    "#requiring that mean(fp[1:3]) = 0 (the null probes have zero fitness)\n",
    "# ab: so, the three null probes are first in the fp array because their names are, or start with, zero, so\n",
    "# they get put at the beginning by an alphabetical sort!\n",
    "# TODO: refactor out this 3\n",
    "mnull<-mean(fp[1:3])\n",
    "\n",
    "fp<-fp-mnull\n",
    "fc<-fc-mnull*2 \n",
    "# fp is at the probe level, but fc is at the *construct* level, and\n",
    "# each *construct* has *two* probes in it; we're subtracting out the value we'd expect for a construct made out of\n",
    "# *two* null probes.  I don't have to refactor out this two, because it is about the construct format \n",
    "# (\"dual\" crispr) not the number of replicates.\n",
    "\n",
    "rank_p<-rep(0,nprobes)\n",
    "names(rank_p)<-probes\n",
    "#find best probes\n",
    "fp12<-fp\n",
    "i<-1 #do null construct\n",
    "# TODO: refactor 3s\n",
    "rank_p[(i-1)*3+1:3]<-rank(abs(fp12[(i-1)*3+1:3])) #looking for the worst\n",
    "\n",
    "# TODO: refactor 3s (for # probes per gene)\n",
    "# The 2 here *isn't* actually number of replicates; it is just that we did first \"gene\"--really the null--\n",
    "# separately above.  The one difference between the equation used for the null and the one use for the \n",
    "# real genes is that for the null, abs is positive, whereas in the equation for the real genes, we are \n",
    "# examining the *negative* of the abs value.  This is because, for the null gene, we expect the real value \n",
    "# of fp for each of its probes to be zero--no effect on fitness.  Rank assigns ranks values in ascending order, so we \n",
    "# make them all positive using abs and say the one closest to zero is the best, the second closest to zero is\n",
    "# the second best, and so forth.  For example, if abs(fp12[1:3]) is 0.290, 0.009, 1.48, then \n",
    "# rank(abs(fp12[1:3])) = 2, 1, 3 since the first value in abs(fp12[1:3]) has a rank of 2 (second-closest to zero),\n",
    "# the econd value in abs(fp12[1:3]) has a rank of 1 (closest to zero), and so forth.\n",
    "# However, for the real genes, we assume that the probe with the fp \n",
    "# value *farthest* from zero is the best probe.  So we make all the fp values positive using abs, then make\n",
    "# those abs values all negative.  Since rank assigns rank values in ascending order, the one with the most negative value\n",
    "# (i.e., the largest absolute value of fp) will be ranked first, etc.\n",
    "for (i in 2:n) { # for each gene, except the first one (which is really the null)\n",
    "   rank_p[(i-1)*3+1:3]<-rank(-abs(fp12[(i-1)*3+1:3])) #looking for the best\n",
    "}\n",
    "\n",
    "#TODO: refactor 3, for number of probes per gene\n",
    "p_rank<-3-rank_p # p_rank has the probes for each gene in reverse order from the way they are in rank_p; thus, the *best* probe in p_rank has the value 2 (3-1) whereas the worst has the value 0 (3-3), while in rank_p, the *best* probe has value 1 and the worst has value 3; it is used only to make the probe rank output file.\n",
    "\n",
    "wpi1<-matrix(0,nrow=nprobes,ncol=nprobes)\n",
    "# for each pair of probes\n",
    "for (i in 1:nprobes) {\n",
    "   for (j in 1:nprobes) {\n",
    "       #TODO: refactor 3s\n",
    "       #err ... subtracting 3 from rank_p will always either give a negative or zero.  But i guess it doesn't matter, as we're subtracting 3 from the rank of *both* probes and then multiplying, so the result will always be either positive or zero\n",
    "      wpi1[i,j]<-(rank_p[i]-3)*(rank_p[j]-3) # product of reversed rank (i.e., best probe has biggest number) for the two probes in this probe pair\n",
    "   }\n",
    "}\n",
    "\n",
    "f<-rep(0,n)\n",
    "names(f)<-genes\n",
    "for (i in 1:n) { # for each gene\n",
    "    # TODO: refactor 3s\n",
    "   w1<-(rank_p[(i-1)*3+1:3]-3)^2 #ansatz for weights # so, subtract 3 from the rank of each of the probes from this gene, then square (squaring since value will be neg or zero--see above?)\n",
    "   f[i]<-sum(w1*fp[(i-1)*3+1:3])/sum(w1) #weighted mean # multiply fp for each probe for this gene by the anzatz weight for that probe, then sum across all the probes for this gene, and divide that sum by the sum of the anzatz weights for all probes for this gene\n",
    "\n",
    "}\n",
    "fmean<-f # fmean is array of zero values, one for each gene\n",
    "\n",
    "pi1<-res2[[3]] #raw pi-scores per construct\n",
    "\n",
    "mean_pi1<-matrix(0,nrow=n,ncol=n)\n",
    "for (i in 1:(n-1)) { # for each first gene \n",
    "    # TODO: refactor 3s\n",
    "   ixi<-3*(i-1)+1:3 # get range of probe indices for first gene \n",
    "   for (j in (i+1):n) { # for each second gene not already covered\n",
    "      ixj<-3*(j-1)+1:3 # get range of probe indices for second gene \n",
    "       # reminder: w0_0 is the \"physical goodness\" of each construct.  Seems to be integer booleans (i.e., 1 for true, 0 for false)\n",
    "      expressed1<-w0_0[ixi,ixj]>0 #define expressed probe pairs # ab: for this pair of genes\n",
    "      \n",
    "      local_w1<-wpi1[ixi,ixj]/sum(wpi1[ixi,ixj][expressed1])*sum(expressed1)\n",
    "       # wait, local_w1 doesn't seem to actually be *used* anywhere ...?\n",
    "       \n",
    "       # the denominator here is clearly just making sure we never get a divide-by-zero error ...\n",
    "       # looks like we're getting mean of the weighted pi values across all expressed probes for this gene\n",
    "      mean_pi1[i,j]<-sum((pi1[ixi,ixj]*wpi1[ixi,ixj])[expressed1])/max(small,sum(wpi1[ixi,ixj][expressed1]))\n",
    "   }\n",
    "}\n",
    "\n",
    "uutri<-upper.tri(mean_pi1)\n",
    "uutri[1,]<-FALSE #remove top line, 0 \n",
    "zi1<-mean_pi1[uutri]\n",
    "zi<-zi1\n",
    "npi<-length(zi1)\n",
    "\n",
    "mmm<-length(fp) # number of probes\n",
    "pi_iter<-matrix(0,nrow=npi,ncol=niter)\n",
    "fp_iter<-matrix(0,nrow=mmm,ncol=niter)\n",
    "f_iter<-matrix(0,nrow=n,ncol=niter)\n",
    "\n",
    "utri<-upper.tri(fc_0)\n",
    "ntri<-sum(utri)\n",
    "ppi_iter<-matrix(0,nrow=ntri,ncol=niter)\n",
    "\n",
    "for (iter in 1:niter) {\n",
    "   cat(\"\\n\",iter,\"\\n\")\n",
    "   \n",
    "   fc_1<-matrix(0,nrow=nprobes,ncol=nprobes) # same starting value as fc_0<-matrix(0,nrow=nprobes,ncol=nprobes)\n",
    "    \n",
    "   # set seed ONLY FOR TESTING\n",
    "   if (gUseSeed == TRUE) {\n",
    "       set.seed(iter)\n",
    "   }\n",
    "   fc0<-fc_0[utri]+rnorm(ntri,sd=sdfc_0[utri]) # ok, previous fc0 was fc0<-fc ; now we're adding a random normal to each fc, where each normal variable's mean is ?the sum of all fcs in the upper triangle?, and its stddev is the stddev of the fc of the analogous construct?\n",
    "   pp0<-pp_0[utri] # gets the posterior probability of the fcs for constructs in the upper triangle\n",
    "    \n",
    "   # set seed ONLY FOR TESTING\n",
    "   if (gUseSeed == TRUE) {\n",
    "       set.seed(iter)\n",
    "   }\n",
    "   draw<-ifelse(runif(ntri)<pp0,1,0) # draw is 1 if the random posterior probability is less than the calculated posterior probability, zero otherwise\n",
    "   fc_1[utri]<-fc0*draw # ok, multiplying by draw will set to zero every value in fc_1 where the posterior probability of the real fc was not more than you'd expect by chance\n",
    "   fc_1<-fc_1+t(fc_1) # make fc_1 symmetric\n",
    "   \n",
    "    \n",
    "   #robust fitting\n",
    "   res2<-irls(fc_1,w0_0,probes,ag=2,tol=1e-3,maxit=50)\n",
    "\n",
    "   fp0<-res2[[1]] #these are probe fitnesses fp\n",
    "\n",
    "   #since fp is determined up to an additive constant, set the constant by \n",
    "   #requiring that mean(fp[1:3]) = 0 (the null probes have zero fitness\n",
    "    # TODO: refactor 3\n",
    "   mnull<-mean(fp0[1:3])\n",
    "   fp0<-fp0-mnull\n",
    "    # end repeat of code\n",
    "   \n",
    "   for (i in 1:n) {\n",
    "       # TODO: refactor 3s\n",
    "      w1<-(rank_p[(i-1)*3+1:3]-3)^2 #ansatz for weights\n",
    "      f_iter[i,iter]<-sum(w1*fp0[(i-1)*3+1:3])/sum(w1) #weighted mean\n",
    "   }\n",
    "   # end near-repeat of code\n",
    "    \n",
    "   pi1<-res2[[3]] #raw pi-scores per construct # repeat code\n",
    "   pi_scrambled<-pi1 # why put pi1 into pi_scrambled, then use it without changing it in any way? It *isn't* scrambled, it is just pi1\n",
    "   \n",
    "    # TODO: repeat of above code to set mean_pi1\n",
    "   mean_pi1<-matrix(0,nrow=n,ncol=n)\n",
    "   for (i in 1:(n-1)) {\n",
    "        # TODO: refactor 3s\n",
    "      ixi<-3*(i-1)+1:3\n",
    "      for (j in (i+1):n) {\n",
    "         ixj<-3*(j-1)+1:3\n",
    "         expressed1<-w0_0[ixi,ixj]>0 #define expressed probe pairs\n",
    "         local_w1<-wpi1[ixi,ixj]/sum(wpi1[ixi,ixj][expressed1])*sum(expressed1)\n",
    "   \n",
    "         mean_pi1[i,j]<-sum((pi_scrambled[ixi,ixj]*wpi1[ixi,ixj])[expressed1])/max(small,sum(wpi1[ixi,ixj][expressed1]))\n",
    "      }\n",
    "   }\n",
    "   zi1<-mean_pi1[uutri]\n",
    "    # end repeat of code\n",
    "   \n",
    "   pi_iter[,iter]<-zi1\n",
    "   fp_iter[,iter]<-fp0\n",
    "}\n",
    "\n",
    "f_mean<-apply(f_iter,1,mean) # one fmean for each gene # wait, this value is never used!  What is output in the single-gene fitness file is f, not f_mean, although the stddev output there is f_sd (see right below)\n",
    "f_sd<-apply(f_iter,1,sd) # output in single gene fitness file\n",
    "\n",
    "fp_mean<-apply(fp_iter,1,mean) # never used\n",
    "fp_sd<-apply(fp_iter,1,sd) # never used\n",
    "\n",
    "pi_mean<-apply(pi_iter,1,mean) # used in several plots, output in pi score file\n",
    "pi_sd<-apply(pi_iter,1,sd) # output in pi score file\n",
    "\n",
    "pi_iter_null<-pi_iter-pi_mean #used directly below, then *redefined* (same way) and used (differently) in prepping for pi score output file\n",
    "\n",
    "pi_null<-c(pi_iter_null,-pi_iter_null) # used directly below, and in histogram of pi scores\n",
    "enull<-ecdf(pi_null) # used in plot of pi scores by fdr\n",
    "emean<-ecdf(pi_mean) # used in plot of pi scores by fdr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram of Pi Scores\n",
    "\n",
    "Smooth curve represents expected distribution given null hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R \n",
    "\n",
    "rge<-range(pi_mean)\n",
    "# TODO: where does 0.002 in break seq come from?  Should we set in params?\n",
    "h<-hist(pi_mean,breaks=seq(rge[1]-0.002,rge[2]+0.002,by=0.002),main=\"\",xlab=expression(pi[\"gg'\"]),col=\"grey80\",border=FALSE,probability=TRUE)\n",
    "   d<-density(pi_null,bw=0.002)\n",
    "   lines(d,col=\"black\")\n",
    "   rug(pi_mean)\n",
    "box()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot of Pi Score by FDR for Left and Right Tails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R \n",
    "\n",
    "fdr_left<-pmin(1,enull(pi_mean)/emean(pi_mean))\n",
    "fdr_right<-pmin(1,(enull(-pi_mean))/(1-emean(pi_mean)))\n",
    "plot(pi_mean,fdr_left,ylim=c(0,1),xlab=expression(pi[\"gg'\"]),ylab=\"FDR, left\") #left tail test\n",
    "plot(pi_mean,fdr_right,ylim=c(0,1),xlab=expression(pi[\"gg'\"]),ylab=\"FDR, right\") #right tail test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pi Score File Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R \n",
    "\n",
    "z<-pi_mean/sd(pi_mean)\n",
    "\n",
    "pi_iter_null<-pi_iter-pi_mean\n",
    "abspi<-abs(pi_mean)\n",
    "PP<-apply(abs(pi_iter_null)<abspi,1,mean)\n",
    "\n",
    "oPP<-order(z)\n",
    "\n",
    "#get names of these gene pairs\n",
    "# These g1//g2, etc hardcodes are ok because represent DUAL crispr genes\n",
    "names_of_g1<-g1names[uutri]\n",
    "fg1<-f[names_of_g1]\n",
    "names_of_g2<-g2names[uutri]\n",
    "fg2<-f[names_of_g2]\n",
    "fg12<-fg1+fg2\n",
    "names_of_gg<-ggnames[uutri]\n",
    "\n",
    "res<-data.frame(names_of_gg,names_of_g1,fg1,names_of_g2,fg2,fg12,pi_mean,pi_sd,PP,abspi,fdr_left,fdr_right,z)\n",
    "# TODO: Let's refactor these colnames, file suffix, and separator somewhere easier to manage\n",
    "colnames(res)<-c(\"gene_gene\",\"geneA\",\"fA\",\"geneB\",\"fB\",\"fA+fB\",\"pi\",\"sd\",\"PP\",\"abs pi\",\"FDR left\",\"FDR right\",\"z\")\n",
    "#TODO: remove format call here; added to aid in testing\n",
    "write.table(format(res[oPP,], digits=14),file=file.path(gScoringDir, paste(project,\"_pi.txt\",sep=\"\")),\n",
    "            sep=\"\\t\",row.names=FALSE,quote=FALSE)\n",
    "#write.table(res[oPP,],file=paste(project,\"_pi.txt\",sep=\"\"),sep=\"\\t\",row.names=FALSE,quote=FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log2 Frequency vs Time Plots for Constructs with Large Fitness File Output\n",
    "\n",
    "The plots are written to a PDF file.  Only constructs with an absolute fitness greater than or equal to the below minfc value are included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R \n",
    "\n",
    "pdf(file.path(gScoringDir, paste(project,\".pdf\",sep=\"\")))\n",
    "par(pty=\"s\",mfrow=c(1,1))\n",
    "plot_fit(x1,a1,fc,ab1,x2,a2,fc,ab2,minfc=0.10)\n",
    "dev.off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Fitness File Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%R \n",
    "\n",
    "resp<-data.frame(pA_pB,fc,sdfc)\n",
    "# TODO: refactor file suffix, separator into easier to manage location\n",
    "write.table(resp,file=file.path(gScoringDir, paste(project,\"_fc.txt\",sep=\"\")),sep=\"\\t\",row.names=FALSE,quote=FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Constructs Below Abundance Threshold in Both Replicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%R print(sum(bad1 & bad2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram of Construct Fitnesses\n",
    "\n",
    "Smooth curve represents fitted density function on data shown as bars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R \n",
    "\n",
    "good<-!bad1 & !bad2\n",
    "\n",
    "rge<-range(fc)\n",
    "# TODO: where do the 0.005s in the break seq come from?  Do they need to be set in params?\n",
    "hh<-hist(fc[!allbad],breaks=seq(rge[1]-0.005,rge[2]+0.005,by=0.005),main=\"construct fitness\",col=\"grey80\",border=FALSE,xlab=expression(f[\"c\"]))\n",
    "d<-density(fc[!allbad],bw=0.01)\n",
    "lines(d$x,d$y*sum(hh$counts)*0.005,col=\"black\")\n",
    "\n",
    "rug(fc[!allbad])\n",
    "abline(h=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots of Experimental and Fitted Frequencies\n",
    "\n",
    "Scatterplots are provided both showing comparisons of frequencies (either fitted or experimental) between any two timepoints of the same replicate.  Additionally, MA plots for each pair of timepoints for each replicate are provided for both fitted and experimental frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%R \n",
    "\n",
    "plot_scatterplots()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probe Rank File Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%R \n",
    "\n",
    "resp<-data.frame(probes,p_rank)\n",
    "# TODO: refactor file suffix, separator into easier to manage location\n",
    "write.table(resp,file=file.path(gScoringDir, paste(project,\"_p.txt\",sep=\"\")),sep=\"\\t\",row.names=FALSE,quote=FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single-Gene Fitness File Output\n",
    "\n",
    "Output includes both fitness and fitness standard deviation for each gene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%R \n",
    "\n",
    "resy<-data.frame(genes,f,f_sd)\n",
    "# TODO: refactor col names, file suffix, separator into easier to manage location\n",
    "colnames(resy)<-c(\"gene\",\"f\",\"sd\")\n",
    "write.table(resy[-1,],file=file.path(gScoringDir, paste(project,\"_f.txt\",sep=\"\")),sep=\"\\t\",row.names=FALSE,quote=FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Gene Fitness Plot\n",
    "\n",
    "Note that since both axes contain the same data, this is equivalent to a rug plot shifted by 45 degrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R \n",
    "\n",
    "# TODO: since this is always on diagonal, should we refactor to be rug plot?\n",
    "\n",
    "rge<-range(f)*1.1 #with some margin\n",
    "plot(f[-1],f[-1],pch=16,cex=0.6,col=\"blue\",xlim=rge,ylim=rge,xlab=expression(f[\"g\"]),ylab=expression(f[\"g\"]),main=\"single-gene fitness\")\n",
    "abline(v=0,h=0,col=\"#000066\")\n",
    "text(f[-1],f[-1],cex=0.6,labels=genes[-1],pos=((rank(f[-1]) %% 2)+1)*2,offset=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}